#IMPORT LIBRARIES
import numpy as np
import pandas as pd
import keras
from keras.models import load_model
import cv2
import skimage
from skimage import transform

#CREATE MODEL
from keras.models import Sequential
from keras.layers import Activation, Dense, Convolution2D, MaxPooling2D, Dropout, Flatten
def get_my_CNN_model_architecture():
    '''
    The network should accept a 96x96 grayscale image as input, and it should output a vector with 30 entries,
    corresponding to the predicted (horizontal and vertical) locations of 15 facial keypoints.
    '''
    model = Sequential()
    model.add(Convolution2D(32, (5, 5), input_shape=(96,96,1), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    model.add(Convolution2D(64, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.1))

    model.add(Convolution2D(128, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.2))

    model.add(Convolution2D(30, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.3))

    model.add(Flatten())

    model.add(Dense(64, activation='relu'))
    model.add(Dense(128, activation='relu'))
    model.add(Dense(256, activation='relu'))
    model.add(Dense(64, activation='relu'))
    model.add(Dense(30))
    
    #DEFINE FUNCTIONS FOR MODEL
    def compile_my_CNN_model(model, optimizer, loss, metrics):
    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)

def train_my_CNN_model(model, X_train, y_train):
    return model.fit(X_train, y_train, epochs=100, batch_size=200, verbose=1, validation_split=0.2)

def save_my_CNN_model(model, fileName):
    model.save(fileName + '.h5')

def load_my_CNN_model(fileName):
    return load_model(fileName + '.h5')
    
#TRAIN MODEL
# Load training set
data=pd.read_csv('C:\\Users\\User\\Desktop\\training.csv')
y_train=data.drop(['Image'],axis=1)
X_train=data['Image']
images=[]
for i in range(0,len(X_train)):
    int_row=np.array(list(map(int,X_train.iloc[i].split(' '))))
    image=np.resize(int_row,(96,96))
    images.append(image)
images=np.array(images)
images=images.reshape(images.shape+(1,))

# Setting the CNN architecture
my_model = get_my_CNN_model_architecture()

# Compiling the CNN model with an appropriate optimizer and loss and metrics
compile_my_CNN_model(my_model, optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])

# Training the model
hist = train_my_CNN_model(my_model, images, y_train)

# Saving the model
save_my_CNN_model(my_model, 'my_model')

    return model;
    
#LOAD AND ARRANGE TEST IMAGES
data=pd.read_csv('C:\\Users\\User\\Desktop\\test.csv')
X_test=data['Image']
images_test=[]
for i in range(0,len(X_test)):
    int_row=np.array(list(map(int,X_test.iloc[i].split(' '))))
    image=np.resize(int_row,(96,96))
    image=image.astype(np.uint8)
    images_test.append(image)
images_test=np.array(images_test)

submission=pd.read_csv('C:\\Users\\User\\Desktop\\SampleSubmission.csv')

#GET OPENCV FACE DETECTOR 
import cv2
import numpy as np

# Load the model built in the previous step
my_model = load_my_CNN_model('my_model')

# Face cascade to detect faces
face_cascade = cv2.CascadeClassifier('C:/Users/User/Anaconda3/envs/opencv-env/Lib/site-packages/cv2/data/haarcascade_frontalface_default.xml')

#DETECT FACES IN ALL TEST IMAGES
faces=[]
for i in range(0,len(images_test)):
    photo=images_test[i]
    #gray = cv2.cvtColor(photo, cv2.COLOR_BGR2GRAY)
    face = face_cascade.detectMultiScale(photo, 1.3, 5)
    faces.append(face)
    
faces_list=[]
for i in range(0,len(images_test)):
    if len(faces[i])>0:
        faces_list.append(faces[i][0])
    else:
        faces_list.append(faces[i])

#USING THE DTECTED FACES, PREDICT KEYPOINTS FOR ALL TEST IMAGES
# Loop over all the faces found in the frame
for i in range(0,len(faces_list)):
        
    
        # Make the faces ready for the model (normalize, resize and stuff)
        #gray_face = gray[y:y+h, x:x+w]
        if len(faces_list[i])>0:
            (x,y,w,h)=faces_list[i]
            color_face = images_test[i][y:y+h, x:x+w]
        else:
            color_face = images_test[i]
        # Normalize to match the input format of the model - Range of pixel to [0, 1]
        color_face_normalized = color_face / 255

        # Resize it to 96x96 to match the input format of the model
        original_shape = color_face.shape # A Copy for future reference
        face_resized = cv2.resize(color_face_normalized, (96, 96), interpolation = cv2.INTER_AREA)
        face_resized_copy = face_resized.copy()
        face_resized = face_resized.reshape(1, 96, 96, 1)

        # Predict the keypoints using the model
        keypoints = my_model.predict(face_resized)

        # De-Normalize the keypoints values
        keypoints = keypoints * 48 + 48

        # Map the Keypoints back to the original image
        face_resized_color = cv2.resize(color_face, (96, 96), interpolation = cv2.INTER_AREA)
        face_resized_color2 = np.copy(face_resized_color)

        # Pair the keypoints together - (x1, y1)
        points = []
        for i, co in enumerate(keypoints[0][0::2]):
            points.append((co, keypoints[0][1::2][i]))
